require("dotenv").config();

const { ChatGoogleGenerativeAI } = require("@langchain/google-genai");
const { ToolMessage, AIMessage } = require("@langchain/core/messages");
const { StateGraph, MessagesAnnotation } = require("@langchain/langgraph");
const { ChatOpenAI } = require("@langchain/openai");
const {
  CreatePlaylist,
  PlayPlaylistSong,
} = require("./tools/playlist.tool.js");
const { FindSong } = require("./tools/playSong.tool.js");
const { SongDetails } = require("./tools/songDetails.tool.js");
const { RecommendSong } = require("./tools/recommend.tool.js");

const tools = {
  CreatePlaylist,
  PlayPlaylistSong,
  FindSong,
  SongDetails,
  RecommendSong,
};


const model = new ChatOpenAI({
  model: "llama-3.3-70b-versatile",   // ya "mixtral-8x7b-32768"
  apiKey: process.env.GROQ_API_KEY,
  configuration: {
    baseURL: "https://api.groq.com/openai/v1",
  },
}).bindTools(Object.values(tools));


const graph = new StateGraph(MessagesAnnotation)


.addNode("tools", async (state, config) => {
  const last = state.messages[state.messages.length - 1];
  const toolCalls = last?.tool_calls || [];

  if (!toolCalls.length) return state;

  const token = config?.configurable?.token;
  console.log("Token in tools node:", token ? "Present" : "Missing");

  const results = await Promise.all(
    toolCalls.map(async (call) => {
      const tool = tools[call.name];
      if (!tool) throw new Error(`Tool ${call.name} not found`);

      console.log("Invoking Tool:", call.name);
      console.log("Args:", call.args);

      const result = await tool.invoke({
        ...call.args,
        token: token
      });

      return new ToolMessage({
        name: call.name,
        content: typeof result === 'string' ? result : JSON.stringify(result),
        tool_call_id: call.id || call.name
      });
    })
  );

  return {
    ...state,
    messages: [...state.messages, ...results]
  };
})

.addNode("chat", async (state) => {
  console.log("Entering chat node", state);
  console.log("Current conversation messages:", state.messages);

  const res = await model.invoke(state.messages);

  console.log("RAW GEMINI RESPONSE:", JSON.stringify(res, null, 2));

  return {
    ...state,
    messages: [...state.messages, res]
  };
})


.addEdge("__start__", "chat")

.addConditionalEdges("chat", (state) => {
  const last = state.messages[state.messages.length - 1];
  console.log("Last AI Message:", last);

  const toolCalls = last?.tool_calls || [];

  if (!toolCalls.length) {
    console.log("No tool call â€” ending");
    return "__end__";
  }

  console.log("Tool Calls Found:", toolCalls);
  return "tools";
})

.addEdge("tools", "chat");



const agent = graph.compile();

module.exports = { agent }; 